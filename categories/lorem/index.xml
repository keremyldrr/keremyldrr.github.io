<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Kerem Yıldırır</title>
        <link>/categories/lorem/</link>
        <description>Latest blog posts from Kerem Yıldırır</description>

        
        <language>en-us</language>
        

        

        

        

        
        <lastBuildDate>Tue, 04 Sep 2018 23:21:09 +0200</lastBuildDate>
        

        
        <atom:link href="/categories/lorem/index.xml" rel="self" type="application/rss+xml" />
        

        
            
        <item>
          <title>3D Real-Time Instance Segmentation with LDLS-YOLACT</title>
          <link>/projects/3d-segmentation/</link>
          <pubDate>Sat, 04 Jul 2020 23:30:14 +0200</pubDate>
          
          <guid>/projects/3d-segmentation/</guid>
          <description>In this project I’ve developed a 3D object detection and tracking pipeline for autonomous driving with Python and ROS without any labeled 3D data. Our hardware were only a Livox mid-100 lidar sensor and a RealSense camera. After calibrating the sensors, the pipeline is as follows:
Get 2D instance segmentation of the current camera image using YOLACT. Update the id numbers of the detected entitites using SORT Project the masks into 3D point cloud using LDLS Compute the 3D bounding boxes for the detected areas.</description>
        </item>
            
        <item>
          <title>Multiple Object Tracking with Tracktor</title>
          <link>/projects/mot/</link>
          <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
          
          <guid>/projects/mot/</guid>
          <description>Implemented vanilla Tracktor with Faster-RCNN using PyTorch. Added a basic motion model and also a reidentificaiton network as the paper suggested for Tracktor++ . Developed using the MOT16 benchmark and achieved following results on the training set.
My results
State of the art Tracktor++ results
Source code can be found here</description>
        </item>
            
        <item>
          <title>Divergence-Free Shape Correspondence with Time Dependent Vector Fields</title>
          <link>/projects/idp/</link>
          <pubDate>Wed, 20 Nov 2019 00:00:00 +0000</pubDate>
          
          <guid>/projects/idp/</guid>
          <description>We are extending the paper “Divergence-Free Shape Correspondence by Deformation” and representing a motion sequence as a time dependent vector field. We solve correspondence and matching problems for the whole sequence during the optimization. Some of the current results can be seen below. Blue is shape is our estimated deformation and orange is the ground truth in the Dynamic FAUST dataset.
Source code will be made available when the project is completed.</description>
        </item>
            
        <item>
          <title>One Table to Count Them All: Parallel Frequency Estimation on Single-Board Computers</title>
          <link>/projects/sketch/</link>
          <pubDate>Sat, 02 Mar 2019 23:30:14 +0200</pubDate>
          
          <guid>/projects/sketch/</guid>
          <description>Abstract: Sketches are probabilistic data structures that can provide approximate results within mathematically proven error bounds while using orders of magnitude less memory than traditional approaches. They are tailored for streaming data analysis on architectures even with limited memory such as single-board computers that are widely exploited for IoT and edge computing. Since these devices offer multiple cores, with efficient parallel sketching schemes, they are able to manage high volumes of data streams.</description>
        </item>
            
        <item>
          <title>Plant Disease Identification</title>
          <link>/projects/plant_disease/</link>
          <pubDate>Tue, 22 Jan 2019 23:21:09 +0200</pubDate>
          
          <guid>/projects/plant_disease/</guid>
          <description>Abstract Detection of plant diseases via computer vision based systems are being used to identify plant diseases promptly, to prevent the spread of the disease. In this work, we present a system for classifying plant diseases from photographs of the diseased parts of the plant. The system is trained using transfer learning on convolutional neural networks (VGGNet) which are trained to classify 38 plant diseases or 11 disease classes. 95.09% average accuracy was obtained on plant-disease classification using PlantVillage dataset.</description>
        </item>
            
        <item>
          <title>Plant  Identification with Deep Learning Ensembles</title>
          <link>/projects/plant_id/</link>
          <pubDate>Tue, 04 Sep 2018 23:21:09 +0200</pubDate>
          
          <guid>/projects/plant_id/</guid>
          <description>Abstract This work describes the plant identification system that we submitted to the ExpertLifeCLEF plant identification campaign in 2018. We fine-tuned two pre-trained deep learning architectures (SeNet and DensNetwork) using images shared by the CLEF organizers in 2017. Our main runs are 4 ensembles obtained with different weighted combinations of the 4 deep learning architectures. The fifth ensemble is based on deep learning features but uses Error Correcting Output Codes (ECOC) as the ensemble.</description>
        </item>
            
        
    </channel>
</rss>
